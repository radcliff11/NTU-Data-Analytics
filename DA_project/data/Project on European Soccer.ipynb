{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE4032 Data Analytic Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "import time\n",
    "import seaborn as sns\n",
    "#handle warnings\n",
    "import warnings\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "#models and validation scores\n",
    "from sklearn import preprocessing,metrics \n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist \n",
    "import scipy.cluster.hierarchy as sch\n",
    "#features selection, dimensionality reduction\n",
    "from sklearn.feature_selection import SelectKBest,chi2, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import the dataset\n",
    "\n",
    "Dataset from Kaggle : **\"European Soccer Database\"**     \n",
    "Source: https://www.kaggle.com/hugomathien/soccer\n",
    "\n",
    "The dataset is in `database.sqlite`; we use the `sqlite3` function to retrieve the data.  \n",
    "Immediately after importing, we take a quick look at the tables avaliable for us to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"  #Insert path here\n",
    "database = path + 'database.sqlite'\n",
    "conn = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of European Soccer Database\n",
    "\n",
    "### Understanding the data set\n",
    "\n",
    "What each of the attributes does and affects the player: \n",
    "https://www.fifauteam.com/fifa-16-attributes/\n",
    "Player/Position inferred from SOFIFA\n",
    "https://www.kaggle.com/hugomathien/soccer/discussion/60282\n",
    "A soccer player has an `overall rating (OR)` as well as `six scores for the key stats (6S)`, each key stat is calculated from a sum of attributes multiplied by their cofficient depending on the importance of that attibute for that stat. Goal Keepers as a standalone determines their overall rating mainly on goal keeping attributes:\n",
    "- Pace :      {sprint_speed, acceleration}\n",
    "- Shooting :  {finishing, long_shots, shot_power, positioning, penalties, volleys, , free_kick_accuracy}\n",
    "- Passing :   {short_passing, vision, crossing, long_passing, curve, free_kick_accuracy}\n",
    "- Dribbling : {dribbling, ball_control, agility, balance}\n",
    "- Defending : {marking, standing_tackle, interceptions, heading_accuracy, sliding_tackle}\n",
    "- Physical :  {strength, stamina, aggression, jumping, reactions}\n",
    "- GoalKeeping : {gk_diving,gk_handling, gk_kicking, gk_positioning, gk_reflexes}\n",
    "- Does not affect overall rating : {overall_rating,potential,preferred_foot,attacking_work_rate,defensive_work_rate}\n",
    "- \n",
    "\n",
    "### Defining a question \n",
    "\n",
    "Knowing that the database is largely built for the purpose of FIFA game we shall look into the players and their attributes.\n",
    "**The objective behind this analysis is to identify the key attributes (or features) that directly affects a player's position class[Attack, Defend, Midfielder, Goal Keeper] in the end goal that this can be used by people in real life to model their attributes and be a direction for improvement in their games. This can be used by coaches to assess their players on which aspect of their game can be improved on based on what they want to achieve for a better training camp.**\n",
    "\n",
    "\n",
    "1. Data Exploration Objective(Understanding the business and the data): \n",
    "    a. Clean Data, Merge External Information from Current Database. \n",
    "        (Player/Position inferred from SOFIFA https://www.kaggle.com/hugomathien/soccer/discussion/60282 )\n",
    "    b. Derive main positions, and main class positions of players.\n",
    "    c. Determine the correlation of this stats to the player's positons [Attack,Defence,Midfielder,Goalkeeper]\n",
    "    d. Build Data to be used for Classification Clustering, Recommendation model (Prepping the data)\n",
    "    \n",
    "2. Classification (Selecting a model Part 1).\n",
    "    Dataset: All Players\n",
    "    The main objective of classification is to see which attributes would matter to determine the players.\n",
    "    a. In our case we used a supervised models (Naive Bayes, Logistic Regression, ANN, SVM, and Ensemble)\n",
    "        1. We are assessing the trade-off between accuracy and speed of the predictions made by this models\n",
    "        2. What can we improve from these models?\n",
    "            a. Feature Selection: Using SelectKBest\n",
    "                a1. What voting classifier is used and why it's important.\n",
    "                a2. Selecting Features that matters most from feature selection done, does it tally and represent what the finding was from the previous data exploration done from Part 1.\n",
    "            b. Dimensionality Reduction: pCA\n",
    "                b1. Will reducing the number of features to test on result in a better trade-off between accuracy and making the data easier to understand?\n",
    "                b2. Does it agree at the number of features that was used from the Feature selection? Meaning does the features selected explained the majority of the data?\n",
    "                \n",
    "3. Clustering (Selecting a model Part 2)\n",
    "    Dataset: Top 50 Players from each class [Classes: Attack, Defence,Midfielder, Goalkeeper]\n",
    "    The main objective of Clustering in this case is to view the top players for their positions and how they are distributed given their stats. Are there players that are misclassified and are playing a certain positional class even though they are marked as another class from the previous database imported (players_position).\n",
    "    a. The K-Cluster objective is to seperate the players into 4 bins[Classes: Attack, Defence,Midfielder, Goalkeeper] and see how well they are distributed,\n",
    "        1. Will there be any misclassification when K-Cluster is used to predict the player's position.\n",
    "        2. Tried Checking the bins using The (People's) Elbow Method to determine optimum bins for it, still came to 4.\n",
    "    b. DBSCAN - Objective is to cluster players based on their stat's similarities and determine which are the players the players being set apart.\n",
    "        1. Reasons for why the players may be set apart from the cluster although they are near. \n",
    "        2. Give a reason why a portion of midfielders are determined as noise, comment on the rest of the noise identified and the main clusters.\n",
    "        \n",
    "4. Reccommendation (Suggest to players what they can train on based on their Objective Class)\n",
    "    a. Based on their stats predict what their most class most likely is\n",
    "    b. Choose between training to become a different class of player or train to be a better player in current situation.\n",
    "        b1. if training for a different class, show what they need to train more on.\n",
    "        b2. if training for their current class, show what they can improve on to emmulate the best in the leagues.\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning and Prepping Data:\n",
    "1. Merge External Information from Current Database and  Player_Position inferred from SOFIFA;\n",
    "2. Prepping Needed Data: Player positions and their position's class\n",
    "3. Players Role (Variation: Players Position), Players Position Class\n",
    "\n",
    "    a. Player Position Class: Defence\n",
    "        CB - Centreback\n",
    "        SW - Sweeper\n",
    "        FB(LB/RB)- Fullback (LeftBack/RightBack)\n",
    "        WB(LWB/RWB)- WingBack (LeftWingBack/RightWingBack)\n",
    "    b. Player Position Class: Midfielders\n",
    "        CM - Midfielders\n",
    "        CDM - Defensive Midfielders\n",
    "        CAM - Attacking Midfielders\n",
    "        WM(LM/RM) - Wide Midfielders (LeftMidfielder/RightMidfielder)\n",
    "    c. Player Position Class: Attackers\n",
    "        CF(CF/ST) - Centre Forward (CentreForward/Striker)\n",
    "        WF(LF/RF) - Wing Forward (LeftForward/RightForward)\n",
    "        WA(LW/RW) - Wing Attacker (LeftWing/RightWing)\n",
    "    d. Player Position Class: Goalkeeper\n",
    "        GK - Goal Keeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_role(pos):\n",
    "    #classify Full backs \n",
    "    if(pos == 'LB') | (pos == 'RB' ):\n",
    "        return \"FB\"\n",
    "    #classify Wing Backs\n",
    "    elif(pos == \"LWB\") | (pos == \"RWB\" ):\n",
    "        return \"WB\"\n",
    "    #classify Defensive mid fielders\n",
    "    elif(pos == \"CDM\"):\n",
    "        return \"DM\"\n",
    "    #classify Defensive mid fielders\n",
    "    elif(pos == \"LM\") | (pos == \"RM\" ):\n",
    "        return \"WM\"\n",
    "    #classify Strikers or centre forward\n",
    "    elif(pos == \"CF\") | (pos == \"ST\" ):\n",
    "        return \"CF\"\n",
    "    #classify Second Strikers\n",
    "    elif(pos == \"LF\" ) | ( pos == \"RF\" ):\n",
    "        return \"WF\"\n",
    "    #Classify Wing Attackers\n",
    "    elif(pos == \"LW\") | ( pos == \"RW\" ):\n",
    "        return \"WA\"\n",
    "    else:\n",
    "        return pos\n",
    "\n",
    "def classify_position_class(pos):\n",
    "    #classify Attackers class\n",
    "    if (pos == 'CF') | (pos == 'WF' ) | (pos == 'WA'):\n",
    "        return \"Attack\"\n",
    "    #classify Defenders \n",
    "    elif(pos == 'CB') | (pos == 'SW' ) | (pos == 'FB') | (pos == 'WB' ):\n",
    "        return \"Defence\"\n",
    "    #classify Midfielders\n",
    "    elif(pos == 'CM') | (pos == 'DM' ) | (pos == 'CAM') | (pos == 'WM' ):\n",
    "        return \"Midfield\"\n",
    "    else:\n",
    "        return \"GoalKeeper\"      \n",
    "    \n",
    "#pLayer_positions contain original data.\n",
    "player_pos_path = \"./data/player_positions.csv\"\n",
    "players_position = pd.read_csv(player_pos_path)\n",
    "#See the original data format from player_position csv file\n",
    "players_position.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The players main position is determine by the value of 1 while his secondary position is determined by 2, 3...,4...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying data: Find the column name per row that is equals to 1. meaning that is the player's main position\n",
    "players_position[\"specific_player_position\"] = (players_position == 1).apply(lambda y: players_position.columns[y.tolist()].tolist(), axis=1)\n",
    "#join resulting list into 1, as im only getting their main position\n",
    "players_position['specific_player_position'] = players_position[\"specific_player_position\"].str.join(',')\n",
    "players_position.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Arrange Player's specific position, role and position's class\n",
    "For Example:\n",
    "A player who has a specific position of LM (Left Midfield) would have a role of Wing Midfield meaning they are either in the Left or Right as Wing Midfielders. The class of this role would also be under mid-fielders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy only playerID and the player's position.\n",
    "players_position = players_position[['playerID', 'specific_player_position']] \n",
    "#define role of players from their position\n",
    "players_position['player_role'] = players_position['specific_player_position'].apply(classify_role)\n",
    "#define class of player from role\n",
    "players_position['player_position_class'] = players_position['player_role'].apply(classify_position_class)\n",
    "#write result to csv\n",
    "#df.to_csv(\"./data/player_positions_cleaned.csv\",index=False)\n",
    "#This is the resulting position, role, and position class for the players.\n",
    "players_position.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Combine Player's positions to Players attributes: See which of player's attributes has highest correlation to their role as football players and overall training.\n",
    "Note: The PlayerID for players_position is equivalent to player_fifa_api_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"  #Insert path here\n",
    "database = path + 'database.sqlite'\n",
    "conn = sqlite3.connect(database)\n",
    "#Merging and exploring Players table with their attributes \n",
    "Player_Attributes = pd.read_sql(\"\"\"SELECT pa.id, pa.player_fifa_api_id, p.player_name, pa.date, pa.overall_rating, pa.potential, pa.preferred_foot, pa.attacking_work_rate, pa.defensive_work_rate, pa.crossing, pa.finishing, pa.heading_accuracy, pa.short_passing, pa.volleys, pa.dribbling, pa.curve, pa.free_kick_accuracy, pa.long_passing, pa.ball_control, pa.acceleration, pa.sprint_speed, pa.agility, pa.reactions, pa.balance, pa.shot_power, pa.jumping, pa.stamina, pa.strength, pa.long_shots, pa.aggression, pa.interceptions, pa.positioning, pa.vision, pa.penalties, pa.marking, pa.standing_tackle, pa.sliding_tackle, pa.gk_diving, pa.gk_handling, pa.gk_kicking, pa.gk_positioning, pa.gk_reflexes\n",
    "                                    FROM Player_Attributes pa\n",
    "                                    INNER JOIN (SELECT player_name, player_fifa_api_id as api FROM Player) p \n",
    "                                    ON pa.player_fifa_api_id = p.api\n",
    "                                    GROUP BY player_name;\"\"\", conn)\n",
    "Player_Attributes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before dropping empty players\n",
    "players = pd.merge(players_position, Player_Attributes, left_on=\"playerID\",right_on=\"player_fifa_api_id\")\n",
    "print(f\"Before dropping empty players without position and empty stats: {players.shape}\")\n",
    "players.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning empty data and in any case if there are players without roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null data points \n",
    "players.isnull().sum(axis=0)\n",
    "#dropping null rows and those with empty roles\n",
    "players = players.dropna()\n",
    "players.isnull().sum(axis=0)\n",
    "players = players[players['player_role'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features into numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process label encode categorical values that may attribute to overall \n",
    "le = preprocessing.LabelEncoder()\n",
    "players['preferred_foot'] = le.fit_transform(players['preferred_foot'])\n",
    "players['attacking_work_rate'] = le.fit_transform(players['attacking_work_rate'])\n",
    "players['defensive_work_rate'] = le.fit_transform(players['defensive_work_rate'])\n",
    "players['player_position_class_cat'] = le.fit_transform(players['player_position_class'])\n",
    "#How many players are left after dropping empty role players and empty attributes\n",
    "players.shape\n",
    "print(f\"After dropping empty players without position and empty stats: {players.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Checking the Statistics of the for all the players, Identifying their quartiles,best and worst for the specific stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_att = player_attributes.drop(columns=['player_position_class_cat'])\n",
    "player_att.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Relationship amongst the Variables\n",
    "\n",
    "Correlation between the variables, followed by all bi-variate jointplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(six_major.corr())\n",
    "fig1, axes = plt.subplots(1, 1, figsize=(20,20))\n",
    "sb.heatmap(player_att.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = player_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Exploring Data: Correlation of the rest of the attributes with Position class and Overall Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all features not might not be attributed to the player position class\n",
    "player_attributes = players.drop(columns=['playerID', 'specific_player_position', 'player_role','id', 'player_fifa_api_id', 'player_name',\n",
    "       'date','player_position_class'])\n",
    "\n",
    "correlation = []\n",
    "for attribute in player_attributes:\n",
    "    atts = []\n",
    "    atts.append(attribute)\n",
    "    att = player_attributes['player_position_class_cat'].corr(player_attributes[attribute])\n",
    "    overall = player_attributes['overall_rating'].corr(player_attributes[attribute])\n",
    "    atts.append(att)\n",
    "    atts.append(overall)\n",
    "    #print(\"%s: %f\" % (attribute, overall))\n",
    "    correlation.append(atts)\n",
    "#Sort the correlation stats from greatest to least\n",
    "correlation_stats = pd.DataFrame(correlation,columns=['Attribute', 'Correlation_Score_PlayerClass','Correlation_Score_Overall']).sort_values(by=['Correlation_Score_PlayerClass'],ascending=False)\n",
    "correlation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "Correlation Coefficient has a range of `[-1, +1]` and `0` would means that there is no correlation at all. From the values above we can tell that the attribute **ball_control** has the highest coefficient comparing to the other 4 attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(correlation_stats.Attribute, correlation_stats.Correlation_Score_PlayerClass, color = 'red', marker = 'o', linewidth = 1)\n",
    "plt.plot(correlation_stats.Attribute, correlation_stats.Correlation_Score_Overall, color = 'blue', marker = 'o', linewidth = 1)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 8)\n",
    "plt.title('Correlation for Player\\'s Role against attributes ', fontsize = 14)\n",
    "plt.xticks(rotation = 80);\n",
    "plt.ylabel('Correlation Value', fontsize = 14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting up the attributes into their respective key score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Prepping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping Data: Classification\n",
    "Seperate features to train on and the target to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns of attributes to train on\n",
    "X_player = players.drop(columns =['playerID','specific_player_position','player_role','player_position_class','id','player_fifa_api_id',\n",
    "                                  'player_name','date','player_position_class_cat'],axis=1)\n",
    "#get columns to predict\n",
    "Y_player = players.filter([\"player_position_class\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping Data for Cluster:Sample Top 50 of each Class\n",
    "Sampling the top 50 of each class type we are going to find out where they are clustered. This is to cluster players based on their stats and see whether they are suited to able to play other position class as well. Example: Christiano Ronaldo is he really an attacker or with his stats can he be a good too defender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top 100 players of each class\n",
    "top_gk = players[players['player_position_class'] == 'GoalKeeper'].sort_values(by=['overall_rating'], ascending=False).head(50)\n",
    "top_attacker = players[players['player_position_class'] == 'Attack'].sort_values(by=['overall_rating'], ascending=False).head(50)\n",
    "top_defender = players[players['player_position_class'] == 'Defence'].sort_values(by=['overall_rating'], ascending=False).head(50)\n",
    "top_mid_fielder = players[players['player_position_class'] == 'Midfield'].sort_values(by=['overall_rating'], ascending=False).head(50)\n",
    "top_attacker.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the top players for the role SW and WF is too low we'll skip clustering those position\n",
    "top_players= pd.concat([top_attacker,top_defender,top_mid_fielder,top_gk])\n",
    "#Save names for later reference\n",
    "names = top_players.player_name\n",
    "player_class = top_players['player_position_class'].str[0]\n",
    "name_and_class = names + '_' + player_class\n",
    "name_and_class = name_and_class.tolist()\n",
    "#Drop all non_stats column\n",
    "top_players = top_players.drop(['player_name','playerID','specific_player_position','player_role','player_position_class','id','player_fifa_api_id','date','player_position_class_cat'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised Classification\n",
    "We are assessing these models below in terms of accuracy and speed in predicting the classes for the players. This will lead to choosing to us choosing which model has a good balance between speed and accuracy. \n",
    "\n",
    "Model chosen in this stage will be used as the model to recommend to players what kind of player class they are classified as and if they want to change what attributes they need to train.\n",
    " 1. Naive Bayes (NB)\n",
    " 2. Support Vector Machine (SVM)\n",
    " 3. Logistic Regression (LR)\n",
    " 4. Artificial Neural Networks (ANN)\n",
    " 5. Ensemble: Combination of NB,SVM and LR and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train and Test Data, based on the player's stats that are alr available (See Prepped Data for Classification for more details)\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X_player,Y_player,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "@ignore_warnings(category=DataConversionWarning)\n",
    "def test_models_NB_SVM_LR_accuracy(train_x, test_x, train_y, test_y):\n",
    "    #Declare models and ensemble\n",
    "    NB = GaussianNB()\n",
    "    LR = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial' ,random_state=3,max_iter =5000)\n",
    "    #ANN = MLPClassifier(random_state=1, max_iter=5000).fit(train_x,train_y.values.ravel())\n",
    "    ANN = MLPClassifier(hidden_layer_sizes=(100,50,), solver='sgd', early_stopping=True, random_state=1, max_iter=5000).fit(train_x, train_y)\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',random_state=1)\n",
    "    #Voting classifiers, num indicates num of model inside\n",
    "    ensemble_voting_classifier = VotingClassifier(estimators=[('gnb', NB), ('lr', LR), ('svm', SVM)], voting ='hard',)\n",
    "    NB.fit(train_x,train_y.values.ravel())\n",
    "    LR.fit(train_x,train_y.values.ravel())\n",
    "    SVM.fit(train_x,train_y.values.ravel())\n",
    "    ensemble_voting_classifier.fit(train_x,train_y.values.ravel())\n",
    "    #Print performance of 3 models and the ensemble \n",
    "    print(\"3 model and ensemble: Accuracy\")\n",
    "    results = []\n",
    "    timings = []\n",
    "    for clf, label in zip([NB, LR, ANN, SVM,ensemble_voting_classifier], ['Naive Bayes', 'Logistic Regression', 'ANN','Support Vector Machine', 'Ensemble']):\n",
    "        start = time.time()\n",
    "        scores = cross_val_score(clf, test_x, test_y, scoring='accuracy', cv=5)\n",
    "        print(\"Accuracy (Std Deviation): %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        print('Time taken:' + '{:.2f}'.format(time.time() - start) + 's')\n",
    "        results.append(scores.mean())\n",
    "        timings.append(round(time.time() - start,4- - int(math.floor(math.log10(abs(time.time() - start))))))\n",
    "    return results, timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Test Classification performance: NB, SVM and LR and Ensemble (Voting class); without feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results,timings = test_models_NB_SVM_LR_accuracy(Train_X, Test_X, Train_Y, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Train_X1, Test_X1, Train_Y1, Test_Y1 = train_test_split(X_player.drop(columns=['gk_diving','gk_handling','gk_kicking','gk_positioning','gk_reflexes']),Y_player,test_size=0.2)\n",
    "results1,timing1 = test_models_NB_SVM_LR_accuracy(Train_X1, Test_X1, Train_Y1, Test_Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature selection using SelectKBest (Univariate Method). Purpose: Score the attributes based on the scoring function used by SelectKBest and pick the number of features to represent the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The scores of features according to SelectKBest using chi2 scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k=38)# chi test take only into account non-negative features and class\n",
    "fit = bestfeatures.fit(X_player,Y_player)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_player.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "featureScores = featureScores.sort_values(by=['Score'],ascending = False)\n",
    "featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_test_model_perf(x_players,y_players,num_best_features):\n",
    "    print(\"For number of best features: \" + str(num_best_features))\n",
    "    ### apply SelectKBest class to extract top k best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=num_best_features)# chi test take only into account non-negative features and class\n",
    "    fit = bestfeatures.fit(x_players,y_players)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(x_players.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    featureScores = featureScores.sort_values(by=['Score'],ascending = False)\n",
    "    #list the features to test\n",
    "    player_attributes_reduced = featureScores.Features.head(num_best_features).to_list()\n",
    "    print(\"Features selected: \")\n",
    "    print(player_attributes_reduced)\n",
    "    #Test\n",
    "    #get columns of attributes to train on\n",
    "    X_player = players.filter(player_attributes_reduced,axis=1)\n",
    "    #get column to predict\n",
    "    Y_player = players.filter([\"player_position_class\"],axis=1)\n",
    "    #Split Train and Test Data\n",
    "    Train_X, Test_X, Train_Y, Test_Y = train_test_split(X_player,Y_player,test_size=0.2)\n",
    "    results = test_models_NB_SVM_LR_accuracy(Train_X, Test_X, Train_Y, Test_Y)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# from 1 to max features\n",
    "features = list(range(1, X_player.columns.nunique()+1))\n",
    "\n",
    "#Save results in a dataframe to plot and see results\n",
    "overall_results = []\n",
    "overall_timings = []\n",
    "for num_features in features:\n",
    "    #record test for this num of features\n",
    "    results = []\n",
    "    results,timings = select_features_test_model_perf(X_player,Y_player,num_features)\n",
    "    results.append(num_features)\n",
    "    #append to list of list\n",
    "    overall_results.append(results)\n",
    "    overall_timings.append(timings)\n",
    "#make data_frame\n",
    "df_result = pd.DataFrame(overall_results,columns=['NB', 'LR', 'ANN', 'SVM', 'Ensemble','Num_features'])\n",
    "df_timings = pd.DataFrame(overall_results,columns=['NB', 'LR', 'ANN', 'SVM', 'Ensemble','Num_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write results to csv\n",
    "# df_result.to_csv(\"./data/feature_reduc_results7.csv\",index=False)\n",
    "# df_timings.to_csv(\"./data/feature_reduc_timings3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read results from csv\n",
    "df_result = pd.read_csv(\"./data/feature_reduc_results5.csv\")\n",
    "df_result1 = pd.melt(df_result,  id_vars =['Num_features'],value_vars=['NB', 'LR','ANN', 'SVM','Ensemble'], value_name='Accuracy')\n",
    "df_timings = pd.read_csv(\"./data/feature_reduc_timings3.csv\")\n",
    "df_timings1 = pd.melt(df_timings,  id_vars =['Num_features'],value_vars=['NB', 'LR','ANN', 'SVM','Ensemble'], value_name='Timing')\n",
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timings1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10: Performing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max1 = df_result1.nlargest(10, ['Accuracy']) \n",
    "max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max1_timing = df_timings1.nlargest(10, ['Timing']) \n",
    "max1_timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Plot graph and decide best number of features to represent stats to predict position class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "colors = ['steelblue', 'green','blue','red','purple']\n",
    "sns.set(font_scale=1.5, style=\"darkgrid\",palette = 'rocket')\n",
    "sns.lineplot(x='Num_features', y='Accuracy',data=df_result1, hue='variable',palette =colors, sort=False)\n",
    "plt.title(\"Accuracy of models SelectKBest\", fontsize = 20) # for title\n",
    "plt.xlabel(\"Number of Features\", fontsize = 25) # label for x-axis\n",
    "plt.ylabel(\"Accuracy of model\", fontsize = 25) # label for y-axis\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)# Put the legend out of the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "colors = ['steelblue', 'green','blue','red','purple']\n",
    "sns.set(font_scale=1.5, style=\"darkgrid\",palette = 'rocket')\n",
    "sns.lineplot(x='Num_features', y='Timing',data=df_timings1, hue='variable',palette =colors, sort=False)\n",
    "plt.title(\"Timings of models SelectKBest\", fontsize = 20) # for title\n",
    "plt.xlabel(\"Number of Features\", fontsize = 25) # label for x-axis\n",
    "plt.ylabel(\"Timings of model\", fontsize = 25) # label for y-axis\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)# Put the legend out of the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coclusion: The peak attributes to choose are around 24. However, what will happen if we choose attributes that made the accuracy go up.\n",
    "SKLearn Features that cause increase in accuracy for Logistic Regression:\n",
    "    1. 3: gk_positioning\n",
    "    2. 6: marking\n",
    "    3. 8: standing_tackle\n",
    "    4. 10: intercept\n",
    "    5. 12-13: volleys,long_shots\n",
    "    6. 15-19: curve, heading_accuracy, free_kick,accuracy,crossing,ball_control\n",
    "    7. 21-22: shot_power,long_passing\n",
    "    8. 27: agility\n",
    "    9. 30: balance\n",
    "    10. 33: attacking_work_rate\n",
    "    11. 36: potential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: Pick 24 Features from SelectKBest. \n",
    "#### Since accuracy at 24 is similiar better than the 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# These are the best features from SelectKBest\n",
    "final_results = select_features_test_model_perf(X_player,Y_player,24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dimensionality Reduction using PCA: Find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# set the tolerance to a large value to make the example faster\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.01)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': [2,10,13,15, 20,24, 30, 35,38],\n",
    "    'logistic__C': np.logspace(-4, 4, 4),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X_player, Y_player)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_player)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(12, 20))\n",
    "ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "         pca.explained_variance_ratio_, '+', linewidth=2)\n",
    "ax0.set_ylabel('PCA explained variance ratio')\n",
    "\n",
    "ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "            linestyle=':', label='Number of components chosen')\n",
    "ax0.legend(prop=dict(size=12))\n",
    "\n",
    "# For each number of components, find the best classifier results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "components_col = 'param_pca__n_components'\n",
    "best_clfs = results.groupby(components_col).apply(\n",
    "    lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "               legend=False, ax=ax1)\n",
    "ax1.set_ylabel('Classification accuracy (val)')\n",
    "ax1.set_xlabel('Number of components chosen')\n",
    "\n",
    "plt.xlim(-1, 70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings: LR/SVM performed best as a standalone model, but Ensembling the models gave the best performance. We can further optimize the models and features to optimum to make better predictions. For features the top 15 features are enough to explain most of the player's position class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets normanlize the data to eliminate redundant data and ensures that good quality clusters are generated which \n",
    "#can improve the efficiency of clustering. It becomes an essential step before clustering as Euclidean distance is \n",
    "#very sensitive to the changes in the differences\n",
    "x_player = top_players.values # numpy array\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled_player = scaler.fit_transform(X_player)\n",
    "X_norm_player = pd.DataFrame(x_scaled_player)\n",
    "pca = PCA(n_components = 15) # 2D PCA for the plot\n",
    "reduced = pd.DataFrame(pca.fit_transform(X_norm_player))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train and Test Data\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X_norm_player,Y_player,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = test_models_NB_SVM_LR_accuracy(Train_X, Test_X, Train_Y, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: As you can see dimensionality reduction for the models had resulted into improvement of it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Clustering: \n",
    "Explore which algorithm performs best and see their behaviour.\n",
    "1. K-means\n",
    "2. DBSCAN\n",
    "     \n",
    "*Take note of Limitation: The player's stats taken is the latest update. Meaning if Player A's stat is 2015 there might be a player being compared that has a stat taken from 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis (PCA)\n",
    "is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare dataset with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_players = top_players.filter(['gk_reflexes', 'gk_diving', 'gk_positioning', 'gk_handling', 'gk_kicking', 'marking', 'sliding_tackle', 'standing_tackle', 'finishing', 'interceptions', 'positioning', 'volleys', 'long_shots', 'dribbling', 'curve', 'heading_accuracy', 'free_kick_accuracy', 'crossing', 'ball_control', 'penalties', 'shot_power', 'long_passing', 'short_passing', 'vision'],axis=1)\n",
    "top_players "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets normanlize the data to eliminate redundant data and ensures that good quality clusters are generated which \n",
    "#can improve the efficiency of clustering. It becomes an essential step before clustering as Euclidean distance is \n",
    "#very sensitive to the changes in the differences\n",
    "x_player = top_players.values # numpy array\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled_player = scaler.fit_transform(x_player)\n",
    "X_norm_player = pd.DataFrame(x_scaled_player)\n",
    "pca = PCA(n_components = 2) # 2D PCA for the plot\n",
    "reduced = pd.DataFrame(pca.fit_transform(X_norm_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of clusters\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "# fit the input data\n",
    "kmeans = kmeans.fit(reduced)\n",
    "# get the cluster labels\n",
    "labels = kmeans.predict(reduced)\n",
    "# centroid values\n",
    "centroid = kmeans.cluster_centers_\n",
    "# cluster values\n",
    "clusters = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced['cluster'] = clusters\n",
    "reduced['name_and_class'] = name_and_class\n",
    "reduced.columns = ['x', 'y', 'cluster', 'name_and_class']\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "def set_size(w,h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "    \n",
    "ax = sns.lmplot(x=\"x\", y=\"y\", hue='cluster', data = reduced, legend=False,\n",
    "                   fit_reg=False, size = 10, scatter_kws={\"s\": 200})\n",
    "\n",
    "texts = []\n",
    "for x, y, s in zip(reduced.x, reduced.y, reduced.name_and_class):\n",
    "    texts.append(plt.text(x, y, s))\n",
    "set_size(10,25)\n",
    "ax.set(ylim=(-1.5, 1.7))\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.xlabel(\"PC 1\", fontsize = 20)\n",
    "plt.ylabel(\"PC 2\", fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Testing for optimal clusters for k-mean: Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2) # 2D PCA for the plot\n",
    "reduced1 = pd.DataFrame(pca.fit_transform(X_norm_player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = [] \n",
    "inertias = [] \n",
    "mapping1 = {} \n",
    "mapping2 = {} \n",
    "K = range(1,12) \n",
    " \n",
    "for k in K: \n",
    "    #Building and fitting the model \n",
    "    kmeanModel = KMeans(n_clusters=k).fit(reduced1) \n",
    "    kmeanModel.fit(reduced1)     \n",
    "      \n",
    "    distortions.append(sum(np.min(cdist(reduced1, kmeanModel.cluster_centers_, \n",
    "                      'euclidean'),axis=1)) / reduced1.shape[0]) \n",
    "    inertias.append(kmeanModel.inertia_) \n",
    "  \n",
    "    mapping1[k] = sum(np.min(cdist(reduced1, kmeanModel.cluster_centers_, \n",
    "                 'euclidean'),axis=1)) / reduced1.shape[0] \n",
    "    mapping2[k] = kmeanModel.inertia_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, distortions, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Distortion') \n",
    "plt.title('The Elbow Method using Distortion') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets normanlize the data to eliminate redundant data and ensures that good quality clusters are generated which \n",
    "#can improve the efficiency of clustering. It becomes an essential step before clustering as Euclidean distance is \n",
    "#very sensitive to the changes in the differences\n",
    "x_player = top_players.values # numpy array\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled_player = scaler.fit_transform(x_player)\n",
    "X_norm_player = pd.DataFrame(x_scaled_player)\n",
    "pca = PCA(n_components = 2) # 2D PCA for the plot\n",
    "reduced2 = pd.DataFrame(pca.fit_transform(X_norm_player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets normanlize the data to eliminate redundant data and ensures that good quality clusters are generated which \n",
    "#can improve the efficiency of clustering. It becomes an essential step before clustering as Euclidean distance is \n",
    "#very sensitive to the changes in the differences\n",
    "x_player = top_players.values # numpy array\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled_player = scaler.fit_transform(x_player)\n",
    "X_norm_player = pd.DataFrame(x_scaled_player)\n",
    "pca = PCA(n_components = 2) # 2D PCA for the plot\n",
    "reduced2 = pd.DataFrame(pca.fit_transform(X_norm_player))\n",
    "# train the model using DBSCAN\n",
    "db = DBSCAN(eps=0.34, min_samples=25)\n",
    "# prediction for dbscan clusters\n",
    "db_clusters = db.fit_predict(reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2['cluster'] = db_clusters\n",
    "reduced2['name_and_class'] = name_and_class\n",
    "reduced2.columns = ['x', 'y', 'cluster', 'name_and_class']\n",
    "reduced2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot DBSCAN\n",
    "sns.set(style=\"white\")\n",
    "ax = sns.lmplot(x=\"x\", y=\"y\", hue='cluster', data = reduced2, legend=False,\n",
    "                   fit_reg=False, size = 10, scatter_kws={\"s\": 200})\n",
    "\n",
    "texts = []\n",
    "for x, y, s in zip(reduced2.x, reduced2.y, reduced2.name_and_class):\n",
    "    texts.append(plt.text(x, y, s))\n",
    "\n",
    "set_size(10,25)\n",
    "ax.set(ylim=(-1.5, 1.7))\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.xlabel(\"PC 1\", fontsize = 20)\n",
    "plt.ylabel(\"PC 2\", fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal eps is around is around 0.315 , min_sample_size =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduced2 = pd.DataFrame(pca.fit_transform(X_norm_player))\n",
    "# train the model using DBSCAN\n",
    "db = DBSCAN(eps=0.24, min_samples=20)\n",
    "# prediction for dbscan clusters\n",
    "db_clusters = db.fit_predict(reduced2)\n",
    "reduced2['cluster'] = db_clusters\n",
    "reduced2['name_and_class'] = name_and_class\n",
    "reduced2.columns = ['x', 'y', 'cluster', 'name_and_class']\n",
    "### Plot DBSCAN\n",
    "sns.set(style=\"white\")\n",
    "ax = sns.lmplot(x=\"x\", y=\"y\", hue='cluster', data = reduced2, legend=False,\n",
    "                   fit_reg=False, size = 10, scatter_kws={\"s\": 200})\n",
    "\n",
    "texts = []\n",
    "for x, y, s in zip(reduced2.x, reduced2.y, reduced2.name_and_class):\n",
    "    texts.append(plt.text(x, y, s))\n",
    "\n",
    "set_size(10,25)\n",
    "ax.set(ylim=(-1.5, 1.7))\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.xlabel(\"PC 1\", fontsize = 20)\n",
    "plt.ylabel(\"PC 2\", fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Recommendation\n",
    "We are going to build an stats viewer for aspiring football players to gauge what kind of class of players suits their stats that the coaches in camp gave them. The purpose of this is to help them to further develop their skills in their chosen class or if they want to switch and train for another class, recommend them what skills they need to work on in order to be more like the players of that class stats wise.\n",
    "\n",
    "How this applies in real life is if this used during training camps it would help coaches and students to develop the skills needed to be able to introduce students to football and train them to become better players. If there would be a standardization to the measurement of this stats, it would help create better insights for coahces and students to help develop a better training programs for schools to help aspiring atheletes visualize their abilities.\n",
    "\n",
    "Parts of the recommendation:\n",
    "   1. Start of training camp (Class Prediction, Player Assesment and Development):\n",
    "            a. 24 features: With 24 attributes predict the player's position class.\n",
    "            b. Decide what skills they need to work on for their desired position.\n",
    "   2. End of training camp (Show improvement):\n",
    "            a. Show improvement to players.\n",
    "            b. Inspire, show top 1% compared to them.\n",
    "            \n",
    "Recap on Stats:\n",
    "1. All Stats.\n",
    "        - Pace :      {sprint_speed, acceleration}\n",
    "        - Shooting :  {finishing, long_shots, shot_power, positioning, penalties, volleys, free_kick_accuracy}\n",
    "        - Passing :   {short_passing, vision, crossing, long_passing, curve}\n",
    "        - Dribbling : {dribbling, ball_control, agility, balance}\n",
    "        - Defending : {marking, standing_tackle, interceptions, heading_accuracy, sliding_tackle}\n",
    "        - Physical :  {strength, stamina, aggression, jumping,reactions}\n",
    "        - GoalKeeping : {gk_diving,gk_handling, gk_kicking, gk_positioning, gk_reflexes}\n",
    "        Excluded\n",
    "        - Does not affect overall rating : {overall_rating,potential,preferred_foot,attacking_work_rate,defensive_work_rate}\n",
    "        \n",
    "2. 24 Included Stats for Prediction in Amateurs:\n",
    "        - Shooting :  {finishing,long_shots,shot_power,positioning, penalties, volleys, free_kick_accuracy}\n",
    "        - Passing : {short_passing,vision,free_kick_accuracy,crossing,long_passing,curve}\n",
    "        - Dribbling : {dribbling,ball_control}\n",
    "        - Defending : {marking, standing_tackle,interceptions,heading_accuracy,sliding_tackle}\n",
    "        - GoalKeeping : {gk_diving,gk_handling, gk_kicking, gk_positioning, gk_reflexes}\n",
    "         - Does not affect overall rating : {overall_rating,potential,preferred_foot,attacking_work_rate,defensive_work_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_players.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at a Professional players Data attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare Model and Feature: Logistic Regression 15 Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "@ignore_warnings(category=DataConversionWarning)\n",
    "def set_up_player_class_model(x_players,y_players,num_best_features):\n",
    "    print(\"For number of best features: \" + str(num_best_features))\n",
    "    ### apply SelectKBest class to extract top k best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=num_best_features)# chi test take only into account non-negative features and class\n",
    "    fit = bestfeatures.fit(x_players,y_players)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(x_players.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    featureScores = featureScores.sort_values(by=['Score'],ascending = False)\n",
    "    #list the features to test\n",
    "    player_attributes_reduced = featureScores.Features.head(num_best_features).to_list()\n",
    "    print(\"Features selected: \")\n",
    "    print(player_attributes_reduced)\n",
    "    #Test\n",
    "    #get columns of attributes to train on\n",
    "    X_player = players.filter(player_attributes_reduced,axis=1)\n",
    "    #get column to predict\n",
    "    Y_player = players.filter([\"player_position_class\"],axis=1)\n",
    "    #Split Train and Test Data\n",
    "    Train_X, Test_X, Train_Y, Test_Y = train_test_split(X_player,Y_player,test_size=0.2)\n",
    "    LR = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial' ,random_state=3,max_iter =5000)\n",
    "    LR.fit(Train_X,Train_Y.values.ravel())\n",
    "    return LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create: Model for predicting  player class at start of training camp: Fast identification for alot of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_24_atts = set_up_player_class_model(X_player,Y_player,24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide Players into their player class: Attack, Defence, Midfield, and Goalkeeper\n",
    "Get the Average stat of the players of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_class in sorted(players.player_position_class.unique()):\n",
    "     print(pos_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Data frame with the average and top 1% of each class\n",
    "class_stats = []\n",
    "column_name = []\n",
    "for pos_class in sorted(players.player_position_class.unique()):\n",
    "    print(pos_class)\n",
    "    player_class = players[players['player_position_class'] == pos_class].sort_values(by=['overall_rating'], ascending=False).drop(columns=['potential','preferred_foot','attacking_work_rate','defensive_work_rate','player_name','playerID','specific_player_position','player_role','player_position_class','id','player_fifa_api_id','date','player_position_class_cat'])\n",
    "    player_summary = player_class.describe(percentiles = [.10, .50, .99,] )\n",
    "    player_summary.insert(0, 'Pos_class', pos_class)\n",
    "    class_stats.append(player_summary.iloc[1,:].to_list())\n",
    "    class_stats.append(player_summary.iloc[6,:].to_list())\n",
    "    column_name = player_summary.columns.to_list()\n",
    "\n",
    "professional_players_stats = pd.DataFrame(class_stats,columns=column_name)\n",
    "professional_players_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of training camp (Class Prediction, Player Assesment and Development):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input 24 features to predict players Stats:\n",
    "Recap on Stats:\n",
    "1. 24 Included Stats for Prediction in Amateurs:\n",
    "        - Shooting(7) :  {finishing,long_shots,shot_power,positioning, penalties, volleys, free_kick_accuracy}\n",
    "        - Passing(5) : {short_passing,vision,crossing,long_passing,curve}\n",
    "        - Dribbling(2) : {dribbling,ball_control}\n",
    "        - Defending(5) : {marking, standing_tackle,interceptions,heading_accuracy,sliding_tackle}\n",
    "        - GoalKeeping(5) : {gk_diving,gk_handling, gk_kicking, gk_positioning, gk_reflexes}\n",
    "arrange to this order\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_item_layout = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-between'\n",
    ")\n",
    "\n",
    "form_items = [\n",
    "    Box([Label(value= r'\\(\\color{Green} {' + 'New Player Attribute'  + '}\\)')], layout=form_item_layout),\n",
    "    #Shooting 7 \n",
    "    Box([Label(value= r'\\(\\color{blue} {' + 'Shooting'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Finishing'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Long shots'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Shot power'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Positioning'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Penalties'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Volleys'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Free Kick Accuracy'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "    #Passing 5 \n",
    "    Box([Label(value=r'\\(\\color{blue} {' + 'Passing'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Short Passing'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Vision'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Crossing'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Long Passing'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Curve'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "    \n",
    "    #Dribbling 2\n",
    "    Box([Label(value=r'\\(\\color{blue} {' + 'Dribbling'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Dribbling'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Ball Control'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "    \n",
    "    #Defending 5\n",
    "    Box([Label(value=r'\\(\\color{blue} {' + 'Defending'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Marking'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Standing Tackle'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Sliding Tackle'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Interceptions'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Heading Accuracy'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "    \n",
    "    #Goal Keeping 5\n",
    "    Box([Label(value=r'\\(\\color{blue} {' + 'Goal Keeping'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Diving'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Handling'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Kicking'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Positioning'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "        Box([Label(value='Reflexes'), IntSlider(min=5, max=100)], layout=form_item_layout),\n",
    "    #Name\n",
    "    Box([Label(value=r'\\(\\color{blue} {' + 'Name of Player'  + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Name'), Textarea()], layout=form_item_layout),\n",
    "]\n",
    "\n",
    "form = Box(form_items, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='solid 2px',\n",
    "    align_items='stretch',\n",
    "    width='50%'\n",
    "))\n",
    "\n",
    "\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare new batch of players\n",
    "new_players = pd.DataFrame(columns=[\n",
    "    'name',\n",
    "    'finishing','long_shots','shot_power','positioning','penalties','volleys','free_kick_accuracy',\n",
    "    'short_passing','vision','crossing','long_passing','curve',\n",
    "    'dribbling','ball_control',\n",
    "    'marking', 'standing_tackle','interceptions','heading_accuracy','sliding_tackle',\n",
    "    'gk_diving','gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes'])\n",
    "\n",
    "def get_new_player():\n",
    "    new_player = []\n",
    "    #Player Name\n",
    "    new_player.append(form.children[31].children[1].value.rstrip(\"\\n\"))\n",
    "    #Shooting 7\n",
    "    new_player.append(form.children[2].children[1].value)\n",
    "    new_player.append(form.children[3].children[1].value)\n",
    "    new_player.append(form.children[4].children[1].value)\n",
    "    new_player.append(form.children[5].children[1].value)\n",
    "    new_player.append(form.children[6].children[1].value)\n",
    "    new_player.append(form.children[7].children[1].value)\n",
    "    new_player.append(form.children[8].children[1].value)\n",
    "    #Passing 5\n",
    "    new_player.append(form.children[10].children[1].value)\n",
    "    new_player.append(form.children[11].children[1].value)\n",
    "    new_player.append(form.children[12].children[1].value)\n",
    "    new_player.append(form.children[13].children[1].value)\n",
    "    new_player.append(form.children[14].children[1].value)                      \n",
    "    #Dribbling 2\n",
    "    new_player.append(form.children[16].children[1].value)\n",
    "    new_player.append(form.children[17].children[1].value)\n",
    "    #Defending 5\n",
    "    new_player.append(form.children[19].children[1].value)\n",
    "    new_player.append(form.children[20].children[1].value)\n",
    "    new_player.append(form.children[21].children[1].value)\n",
    "    new_player.append(form.children[22].children[1].value)\n",
    "    new_player.append(form.children[23].children[1].value)\n",
    "    #Goal Keeping 5\n",
    "    new_player.append(form.children[25].children[1].value)\n",
    "    new_player.append(form.children[26].children[1].value)\n",
    "    new_player.append(form.children[27].children[1].value)\n",
    "    new_player.append(form.children[28].children[1].value)\n",
    "    new_player.append(form.children[29].children[1].value)\n",
    "    \n",
    "    #Add player to new players\n",
    "    new_players.loc[len(new_players), :] = new_player\n",
    "    new_players.append(new_player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call this function everytime you want to add a new player after shifting the input parameters above\n",
    "new_player = get_new_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict New Batch of Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_players = new_players.drop(columns=['player_initial_position'])\n",
    "new_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Players their initial classes\n",
    "new_players['player_initial_position'] = model_24_atts.predict(new_players.drop(columns=['name']))\n",
    "new_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save \n",
    "#new_players.to_csv('./data/new_players.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion from Initial Prediction: As you can see none of the players are predicted good enough to be a league level attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join profesionnal players and marvin for easier comparisson of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professional_players_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_player_stats(professional_player,player,loc):\n",
    "    compare_player1 = professional_player.copy()\n",
    "    compare_player1 = compare_player1.filter(['Pos_class','gk_reflexes', 'gk_diving', 'gk_positioning', 'gk_handling', 'gk_kicking', 'marking', 'sliding_tackle', 'standing_tackle', 'finishing', 'interceptions', 'positioning', 'volleys', 'long_shots', 'dribbling', 'curve', 'heading_accuracy', 'free_kick_accuracy', 'crossing', 'ball_control', 'penalties', 'shot_power', 'long_passing', 'short_passing', 'vision'])\n",
    "    compare_player1 = compare_player1.reindex(sorted(compare_player1.columns), axis=1)\n",
    "    compare_player1 = compare_player1.append(player.drop(columns=['player_initial_position']).iloc[loc,:])\n",
    "    ##Arrange player_stats column in this order\n",
    "    compare_player1 = compare_player1[['Pos_class','finishing','long_shots','shot_power','positioning', 'penalties', 'volleys', 'free_kick_accuracy',\n",
    "  'short_passing','vision','crossing','long_passing','curve',\n",
    "  'dribbling','ball_control',\n",
    "  'marking', 'standing_tackle','interceptions','heading_accuracy','sliding_tackle',\n",
    "  'gk_diving','gk_handling', 'gk_kicking', 'gk_positioning','gk_reflexes',]]\n",
    "    \n",
    "    return compare_player1\n",
    "def plot_radar(idx):\n",
    "    # categories\n",
    "    categories = compare_stats.iloc[idx,1:].index.tolist()\n",
    "    N = len(categories) # get number of categories\n",
    "    \n",
    "    # values\n",
    "    values= compare_stats.iloc[idx,1:].values.tolist()\n",
    "    values += values[:1] # repeat first value to close poly\n",
    "    # calculate angle for each category\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1] # repeat first angle to close poly\n",
    "    # plot\n",
    "    plt.polar(angles, values, marker='.') # lines\n",
    "    plt.fill(angles, values, alpha=0.3) # area\n",
    "    # xticks\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "    # yticks\n",
    "    ax.set_rlabel_position(0) # yticks position\n",
    "    plt.yticks([20,40,60,80,100], color=\"grey\", size=10)\n",
    "    plt.ylim(0,100)\n",
    "def show_player_vs_league():\n",
    "    #league_avg at position of player\n",
    "    idx1 = 8\n",
    "    #current_player\n",
    "    idx2 = 0\n",
    "    #desire_position league avg\n",
    "    idx3 = 2\n",
    "    #desire_position league avg\n",
    "    idx4 = 4\n",
    "    #desire_position league avg\n",
    "    idx5 = 6\n",
    "\n",
    "    #Player position to compare\n",
    "    fig = plt.figure(figsize=(25,25))\n",
    "    # radar 1:\n",
    "    #idx1 = index of new player to compare to \n",
    "    ax = plt.subplot(221, polar=\"True\")\n",
    "    plt.title('Attacker',color='blue',fontsize=20)\n",
    "    plot_radar(idx1)\n",
    "    plot_radar(idx2)\n",
    "\n",
    "    #radar2:\n",
    "    #idx2 = index of league player to compare to \n",
    "    ax = plt.subplot(222, polar=\"True\")\n",
    "    plt.title('Defender',color='blue',fontsize=20)\n",
    "    plot_radar(idx1)\n",
    "    plot_radar(idx3)\n",
    "\n",
    "    #radar2:\n",
    "    #idx2 = index of league player to compare to \n",
    "    ax = plt.subplot(223, polar=\"True\")\n",
    "    plt.title('Goal Keeper',color='blue',fontsize=20)\n",
    "    plot_radar(idx1)\n",
    "    plot_radar(idx4)\n",
    "\n",
    "    #radar2:\n",
    "    #idx2 = index of league player to compare to \n",
    "    ax = plt.subplot(224, polar=\"True\")\n",
    "    plt.title('Mid-Fielder',color='blue',fontsize=20)\n",
    "    plot_radar(idx1)\n",
    "    plot_radar(idx5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_stats  = compare_player_stats(professional_players_stats,new_players,8)\n",
    "compare_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the new players stats against league average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "form_item_layout = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-between'\n",
    ")\n",
    "\n",
    "form_items = [\n",
    "    Box([Label(value= r'\\(\\color{Green} {' + 'Player'  + ' index' + '}\\)')], layout=form_item_layout),\n",
    "        Box([Label(value='Index'), IntSlider(min=0, max=int(new_players.name.count()-1))], layout=form_item_layout),]\n",
    "\n",
    "form1 = Box(form_items, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='solid 2px',\n",
    "    align_items='stretch',\n",
    "    width='50%'\n",
    "))\n",
    "\n",
    "\n",
    "form1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare league vs the new players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_stats  = compare_player_stats(professional_players_stats,new_players,form1.children[1].children[1].value)\n",
    "show_player_vs_league()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During Training Camp: \n",
    "The players would then choose whether to train in the position they are good in or develop their skills towards their desired position. Lets see if the training will make a difference in the end.\n",
    "\n",
    "In our example we would pick Martin Gaye: predicted to be a mid-fielder but he aspires to be an attacker lets see if training him to be an attacker will make him become one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Marvin: Where he is at now vs league standard at his position vs his aspired position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Marvin his current Progress: Is he good enough to be an attacker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call this function everytime you want to add a new player after shifting the input parameters above\n",
    "marvin_gaye_new = get_new_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
